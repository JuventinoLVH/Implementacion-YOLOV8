{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO V8\n",
    "--- \n",
    "Ejemplo de implementacion\n",
    "\n",
    "#LINKS:\n",
    "\n",
    "#https://github.com/ultralytics/ultralytics\n",
    "\n",
    "#https://github.com/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb\n",
    "\n",
    "#https://www.kaggle.com/code/ultralytics/yolov8/notebook\n",
    "\n",
    "Ejemplo del uso del SDK para/ Python\n",
    "\n",
    "#https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/train-yolov8-object-detection-on-custom-dataset.ipynb\n",
    "\n",
    "\n",
    "Ejemplo de como usar el SDK en python \n",
    "https://towardsdatascience.com/yolo-object-detection-with-opencv-and-python-21e50ac599e9\n",
    "\n",
    "\n",
    "Ejemplo de python, yolo y OpenCV\n",
    "https://omes-va.com/deteccion-de-objetos-yolov3-dnn-opencv-python/\n",
    "\n",
    "Documentacion de como usar de Python, Yolo y OpenCV, muy muy denso pero muy muy completo\n",
    "https://opencv-tutorial.readthedocs.io/en/latest/yolo/yolo.html\n",
    "\n",
    "Una discucion de la comunidad que podria servir\n",
    "https://github.com/ultralytics/yolov5/issues/388\n",
    "\n",
    "#Para el conteo: https://www.youtube.com/watch?v=QWrP77qXEMA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`Implementacion del tutorial que hay en el colab`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\te524132\\Documents\\YOLOV8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "\n",
    "print(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20  Python-3.7.16 torch-1.13.1+cpu CPU\n",
      "Setup complete  (8 CPUs, 15.7 GB RAM, 200.0/237.9 GB disk)\n"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to yolov8n.pt...\n",
      "100%|██████████| 6.23M/6.23M [00:02<00:00, 3.23MB/s]\n",
      "\n",
      "Ultralytics YOLOv8.0.20  Python-3.7.16 torch-1.13.1+cpu CPU\n",
      "\u001b[34m\u001b[1myolo\\engine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=coco128.yaml, epochs=3, patience=50, batch=16, imgsz=640, save=True, cache=False, device=, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=False, val=True, save_json=False, save_hybrid=False, conf=0.001, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=ultralytics/assets/, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, boxes=True, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.001, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, v5loader=False, save_dir=runs\\detect\\train\n",
      "\n",
      "Dataset 'coco128.yaml' not found , missing paths ['C:\\\\Users\\\\te524132\\\\Documents\\\\YOLOV8\\\\datasets\\\\coco128\\\\images\\\\train2017']\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
      "100%|██████████| 6.66M/6.66M [00:01<00:00, 3.74MB/s]\n",
      "Dataset download success  (3.6s), saved to \u001b[1mC:\\Users\\te524132\\Documents\\YOLOV8\\datasets\u001b[0m\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to C:\\Users\\te524132\\AppData\\Roaming\\Ultralytics\\Arial.ttf...\n",
      "100%|██████████| 755k/755k [00:00<00:00, 1.38MB/s]\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.Conv                  [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.Conv                  [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.C2f                   [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.Conv                  [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.C2f                   [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.Conv                  [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.C2f                   [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.Conv                  [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.C2f                   [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.SPPF                  [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.C2f                   [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.C2f                   [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.Conv                  [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.C2f                   [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.Conv                  [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.C2f                   [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.Detect                [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\te524132\\Documents\\YOLOV8\\datasets\\coco128\\labels\\train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<00:00, 696.49it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\te524132\\Documents\\YOLOV8\\datasets\\coco128\\labels\\train2017.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\te524132\\Documents\\YOLOV8\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        1/3         0G      1.166      1.386      1.217        215        640: 100%|██████████| 8/8 [03:35<00:00, 26.90s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [01:41<00:00, 25.36s/it]\n",
      "                   all        128        929       0.65      0.549      0.617      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        2/3         0G      1.182      1.427      1.255        185        640: 100%|██████████| 8/8 [04:21<00:00, 32.66s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [00:55<00:00, 13.84s/it]\n",
      "                   all        128        929      0.677      0.584      0.646       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "        3/3         0G      1.173      1.319       1.25        246        640: 100%|██████████| 8/8 [04:40<00:00, 35.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [01:12<00:00, 18.21s/it]\n",
      "                   all        128        929       0.68       0.59      0.657      0.488\n",
      "\n",
      "3 epochs completed in 0.281 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.5MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.20  Python-3.7.16 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 4/4 [01:17<00:00, 19.35s/it]\n",
      "                   all        128        929       0.68       0.59      0.657      0.488\n",
      "                person        128        254      0.753      0.669       0.76      0.539\n",
      "               bicycle        128          6      0.772      0.333      0.386      0.264\n",
      "                   car        128         46      0.805      0.217      0.332      0.186\n",
      "            motorcycle        128          5      0.685        0.8       0.92      0.752\n",
      "              airplane        128          6      0.741      0.959      0.955       0.75\n",
      "                   bus        128          7       0.75      0.714      0.734      0.656\n",
      "                 train        128          3      0.679          1      0.913      0.855\n",
      "                 truck        128         12      0.966        0.5      0.527      0.354\n",
      "                  boat        128          6      0.342      0.167      0.429      0.291\n",
      "         traffic light        128         14       0.66      0.214      0.226      0.142\n",
      "             stop sign        128          2      0.688          1      0.995      0.721\n",
      "                 bench        128          9      0.759      0.556      0.683      0.532\n",
      "                  bird        128         16       0.88      0.875      0.956      0.618\n",
      "                   cat        128          4      0.684          1      0.895      0.697\n",
      "                   dog        128          9      0.555      0.778      0.803      0.578\n",
      "                 horse        128          2      0.688          1      0.995      0.484\n",
      "              elephant        128         17      0.773      0.941      0.942      0.751\n",
      "                  bear        128          1      0.536          1      0.995      0.995\n",
      "                 zebra        128          4       0.86          1      0.995      0.965\n",
      "               giraffe        128          9       0.78          1      0.973      0.708\n",
      "              backpack        128          6      0.647      0.333      0.467      0.263\n",
      "              umbrella        128         18      0.658      0.536      0.689      0.449\n",
      "               handbag        128         19          1      0.117       0.27      0.149\n",
      "                   tie        128          7      0.775      0.714      0.739      0.519\n",
      "              suitcase        128          4      0.773      0.865      0.895      0.569\n",
      "               frisbee        128          5      0.759        0.8      0.759      0.655\n",
      "                  skis        128          1      0.747          1      0.995      0.497\n",
      "             snowboard        128          7      0.468      0.714      0.666       0.48\n",
      "           sports ball        128          6      0.711      0.421      0.556      0.276\n",
      "                  kite        128         10      0.645      0.548      0.554      0.204\n",
      "          baseball bat        128          4      0.447      0.421      0.252      0.127\n",
      "        baseball glove        128          7      0.692      0.429      0.431      0.303\n",
      "            skateboard        128          5      0.768        0.6        0.6        0.4\n",
      "         tennis racket        128          7      0.731      0.396      0.534      0.331\n",
      "                bottle        128         18      0.515      0.444      0.465      0.274\n",
      "            wine glass        128         16      0.513      0.562      0.597      0.346\n",
      "                   cup        128         36      0.661      0.326      0.434      0.317\n",
      "                  fork        128          6       0.64      0.167      0.191      0.167\n",
      "                 knife        128         16      0.597        0.5      0.616      0.368\n",
      "                 spoon        128         22      0.576      0.186      0.347      0.202\n",
      "                  bowl        128         28      0.568      0.643      0.654      0.532\n",
      "                banana        128          1          0          0      0.199     0.0647\n",
      "              sandwich        128          2          1      0.782      0.995      0.995\n",
      "                orange        128          4          1      0.395      0.828      0.535\n",
      "              broccoli        128         11      0.484      0.258      0.277       0.23\n",
      "                carrot        128         24      0.693      0.564       0.74      0.487\n",
      "               hot dog        128          2      0.461          1      0.995      0.946\n",
      "                 pizza        128          5      0.746          1      0.995      0.834\n",
      "                 donut        128         14      0.633          1      0.941      0.857\n",
      "                  cake        128          4      0.852          1      0.995       0.89\n",
      "                 chair        128         35       0.57      0.543      0.489      0.297\n",
      "                 couch        128          6      0.362        0.5      0.599      0.471\n",
      "          potted plant        128         14      0.648      0.643      0.717       0.48\n",
      "                   bed        128          3      0.911          1      0.995      0.798\n",
      "          dining table        128         13      0.507      0.615      0.503      0.403\n",
      "                toilet        128          2          1      0.948      0.995      0.946\n",
      "                    tv        128          2      0.479        0.5      0.745      0.696\n",
      "                laptop        128          3          1          0      0.487      0.396\n",
      "                 mouse        128          2          1          0     0.0483    0.00483\n",
      "                remote        128          8      0.809        0.5      0.582      0.514\n",
      "            cell phone        128          8          0          0     0.0878      0.046\n",
      "             microwave        128          3      0.594          1      0.753       0.62\n",
      "                  oven        128          5      0.518        0.4       0.41      0.302\n",
      "                  sink        128          6      0.311      0.167      0.385      0.198\n",
      "          refrigerator        128          5      0.643        0.4      0.654      0.525\n",
      "                  book        128         29      0.689      0.172      0.403      0.228\n",
      "                 clock        128          9      0.883      0.889       0.92       0.77\n",
      "                  vase        128          2      0.489          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.497      0.149\n",
      "            teddy bear        128         21      0.749      0.569      0.643      0.412\n",
      "            toothbrush        128          5          1      0.571      0.826      0.527\n",
      "Speed: 6.1ms pre-process, 535.1ms inference, 0.0ms loss, 12.8ms post-process per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Ultralytics YOLOv8.0.20  Python-3.7.16 torch-1.13.1+cpu CPU\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\te524132\\Documents\\YOLOV8\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:35<00:00,  4.40s/it]\n",
      "                   all        128        929      0.665      0.594      0.654      0.486\n",
      "                person        128        254      0.743      0.669      0.763      0.541\n",
      "               bicycle        128          6       0.76      0.333      0.383      0.262\n",
      "                   car        128         46      0.799      0.217      0.333      0.186\n",
      "            motorcycle        128          5      0.628        0.8       0.92      0.752\n",
      "              airplane        128          6      0.742      0.961      0.955       0.75\n",
      "                   bus        128          7       0.76      0.714      0.734      0.656\n",
      "                 train        128          3      0.677          1      0.913      0.855\n",
      "                 truck        128         12      0.939        0.5      0.528      0.356\n",
      "                  boat        128          6      0.252      0.168      0.443      0.255\n",
      "         traffic light        128         14      0.652      0.214      0.229      0.144\n",
      "             stop sign        128          2      0.685          1      0.995      0.721\n",
      "                 bench        128          9      0.755      0.556      0.683      0.532\n",
      "                  bird        128         16      0.878      0.875      0.955      0.617\n",
      "                   cat        128          4      0.632          1      0.895      0.697\n",
      "                   dog        128          9      0.554      0.778      0.803      0.578\n",
      "                 horse        128          2      0.685          1      0.995      0.492\n",
      "              elephant        128         17      0.773      0.941      0.942      0.751\n",
      "                  bear        128          1      0.534          1      0.995      0.995\n",
      "                 zebra        128          4       0.86          1      0.995      0.953\n",
      "               giraffe        128          9      0.725          1      0.968      0.695\n",
      "              backpack        128          6      0.488      0.333      0.459      0.281\n",
      "              umbrella        128         18       0.66      0.539      0.687      0.448\n",
      "               handbag        128         19          1      0.119       0.27      0.148\n",
      "                   tie        128          7      0.773      0.714      0.739      0.519\n",
      "              suitcase        128          4      0.775      0.874      0.895      0.569\n",
      "               frisbee        128          5       0.75        0.8      0.758      0.655\n",
      "                  skis        128          1      0.743          1      0.995      0.497\n",
      "             snowboard        128          7      0.462      0.714      0.665      0.479\n",
      "           sports ball        128          6      0.712      0.424      0.544       0.27\n",
      "                  kite        128         10      0.647      0.554      0.555      0.204\n",
      "          baseball bat        128          4      0.293       0.25      0.199      0.111\n",
      "        baseball glove        128          7      0.666      0.429       0.43      0.303\n",
      "            skateboard        128          5      0.807        0.6      0.599      0.396\n",
      "         tennis racket        128          7      0.732      0.397      0.534      0.331\n",
      "                bottle        128         18      0.467      0.444      0.446      0.277\n",
      "            wine glass        128         16      0.523      0.562      0.569      0.338\n",
      "                   cup        128         36      0.667       0.39      0.449      0.324\n",
      "                  fork        128          6      0.615      0.167      0.195       0.17\n",
      "                 knife        128         16       0.48        0.5      0.599      0.373\n",
      "                 spoon        128         22      0.691      0.205      0.362      0.215\n",
      "                  bowl        128         28      0.634       0.75      0.688      0.548\n",
      "                banana        128          1          0          0      0.142     0.0827\n",
      "              sandwich        128          2          1      0.891      0.995      0.995\n",
      "                orange        128          4          1      0.402      0.788      0.507\n",
      "              broccoli        128         11      0.363       0.21      0.276      0.224\n",
      "                carrot        128         24      0.728      0.669      0.732      0.472\n",
      "               hot dog        128          2      0.585          1      0.828      0.796\n",
      "                 pizza        128          5      0.758          1      0.995      0.834\n",
      "                 donut        128         14      0.633          1      0.941      0.852\n",
      "                  cake        128          4      0.737          1      0.995       0.89\n",
      "                 chair        128         35      0.581      0.543      0.475      0.289\n",
      "                 couch        128          6      0.434      0.667      0.705      0.568\n",
      "          potted plant        128         14      0.645      0.643      0.717       0.48\n",
      "                   bed        128          3      0.754          1      0.995      0.839\n",
      "          dining table        128         13       0.51      0.615      0.512      0.417\n",
      "                toilet        128          2          1      0.951      0.995      0.946\n",
      "                    tv        128          2      0.472        0.5      0.745      0.696\n",
      "                laptop        128          3          1          0       0.44      0.373\n",
      "                 mouse        128          2          1          0     0.0894    0.00894\n",
      "                remote        128          8      0.807        0.5      0.597      0.523\n",
      "            cell phone        128          8          0          0     0.0881     0.0461\n",
      "             microwave        128          3      0.566      0.887      0.753      0.601\n",
      "                  oven        128          5      0.517        0.4      0.399      0.299\n",
      "                  sink        128          6      0.367      0.167      0.392      0.173\n",
      "          refrigerator        128          5       0.62        0.4      0.671      0.532\n",
      "                  book        128         29      0.556      0.172      0.399       0.23\n",
      "                 clock        128          9       0.88      0.889       0.92       0.77\n",
      "                  vase        128          2      0.482          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.497      0.149\n",
      "            teddy bear        128         21       0.75      0.573       0.64       0.41\n",
      "            toothbrush        128          5      0.884        0.6      0.846      0.494\n",
      "Speed: 2.8ms pre-process, 241.3ms inference, 0.0ms loss, 7.2ms post-process per image\n",
      "Ultralytics YOLOv8.0.20  Python-3.7.16 torch-1.13.1+cpu CPU\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 123] The filename, directory name, or volume label syntax is incorrect: 'https:\\\\ultralytics.com\\\\images\\\\bus.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21124\\2181632666.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coco128.yaml'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# evaluate model performance on the validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://ultralytics.com/images/bus.jpg'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# predict on an image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0msuccess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'onnx'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# export the model to ONNX format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, source, stream, verbose, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\site-packages\\ultralytics\\yolo\\engine\\model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, source, stream, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# only update args if predictor is already setup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msmart_inference_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, source, model, verbose, stream)\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# merge list of Result into one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[1;34m(self, source, model, verbose)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;31m# setup source. Run every time predict is called\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;31m# check if save_dir/ label file exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_txt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"setup model before setting up source!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;31m# source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwebcam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreenshot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_source\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[1;31m# model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\site-packages\\ultralytics\\yolo\\engine\\predictor.py\u001b[0m in \u001b[0;36mcheck_source\u001b[1;34m(self, source)\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mscreenshot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'screen'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_url\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# download\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[0mfrom_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\site-packages\\ultralytics\\yolo\\utils\\checks.py\u001b[0m in \u001b[0;36mcheck_file\u001b[1;34m(file, suffix)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0mcheck_suffix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# optional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# convert to str()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http:/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'https:/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# download\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\pathlib.py\u001b[0m in \u001b[0;36mis_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \"\"\"\n\u001b[0;32m   1386\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1387\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mS_ISREG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mst_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1388\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\te524132\\Anaconda3\\envs\\yolo_v8\\lib\\pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1181\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \"\"\"\n\u001b[1;32m-> 1183\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 123] The filename, directory name, or volume label syntax is incorrect: 'https:\\\\ultralytics.com\\\\images\\\\bus.jpg'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "# Se crea un archivo en blanco\n",
    "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
    "# Descarga y carga una red pre-entrenada, nuestro trabajo es re entrenarla con nuestros datos.\n",
    "# esta red pre-entrenada aparte de tener los pesos, tiene las clasificaciones y todo lo demas\n",
    "# se puede omitir, puede que las clases anteriores esten metiendo mucho ruido.\n",
    "# los diferentes tipos de redes pre-entrenadas los puedes ver en el git hub\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    " \n",
    "# Use the model\n",
    "# Esta celda esta comentada porque tarda aprox 30 minutos en entrenar, ademas es \n",
    "# pertinente usar nuestro dataset de una vez. \n",
    "# results = model.train(data='coco128.yaml', epochs=1)  # train the model\n",
    "results = model.val()  # evaluate model performance on the validation set\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "`Implementacion del modelo - Primera parte !!!`\n",
    "\n",
    "Para implementar el modelo se usara la webcam de la laptop.\n",
    "para todo lo relacionado al procesamiento de imagenes se usara OpenCV, en python se importa como `cv2`\n",
    "\n",
    "La siguiente linea de comando *guarda* una camara como si fuera una variable (Faaaaaaaaaak que podeeer)\n",
    "el parametro  **'0'** es por convencion la camara integrada del dispositivo (Usualmente la webcam), pero si nuestro dispositivo pudieramos acceder a el cambiando ese valor.  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "webcam = cv.VideoCapture(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Ahora toca mostrar lo que la webcam ve. Para esto usaremos un ciclo infinito. \n",
    "\n",
    "- El comando ` read()` devuelve un valor booleando indicando si la camara esta disponible y el frame actual\n",
    "\n",
    "- `imshow` pinta el frame, el primer parametro es el nombre de la ventana y el segundo el frame a pintar. \n",
    "\n",
    "- `WaitKey()` es muy importante, pues el ciclo itera mucho mas rapido de lo que la camara puede captar frames, esto hace que el comando imshow se sature. El parametro **'1'** indica que se espere al siguiente frame (Si se pone \"2\" espera 2 frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21124\\2397439584.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexito\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Webcam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    exito , frame = webcam.read()\n",
    "    if not exito :\n",
    "        break\n",
    "    cv.imshow(\"Webcam\", frame)\n",
    "    cv.waitKey(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Lo ultimo que hay que hacer es liberar la camara y borrar todas las ventanas.\n",
    "Si no liberas la camara no puede ser usada por otras instancias. \n",
    "Y si no destruyes las ventanas, ni picandole a la \"x\" las vas a poder cerrar  \n",
    "\n",
    "NOTA: Para parrar la corrida se recomienda codificar para que se cierre automaticamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "`Implementando el modelo que se acaba de entrenar !!`\n",
    "\n",
    "Primero hay que cargat el \".pt\" para los pesos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YOLO_path = HOME + \"runs/detect/train/weights/best.pt\"\n",
    "\n",
    "modelo = YOLO(YOLO_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "`Obteniendo las mimagenes`\n",
    "\n",
    "Para obtener las imagenes se sara openCV. \n",
    "\n",
    "Aqui hice trampa pues estoy abusando del **YOLO**. La instruccion `model(frame)` da como resultad un arreglo con todos los objetos, lo ideal es hacer algo como lo que se hizo en el ejemplo de python, yolo y opencv. Pero no se donde conseguir los archivos **.cfg** ni los **labels**.\n",
    "\n",
    "Supongo que se puede hacer algo como \n",
    "\n",
    "> `model.export(config)`\n",
    "\n",
    "pero no estoy seguro, es tarea para otro dia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam = cv.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede ser un poco lento, sugiero correr desde la linea de comandos la implementacion del yolo en python.\n",
    "Es un poco mas rapida. Si lo corres, lo mas probable es que tengas que matar la terminal para poder terminar con el video D: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    exito , frame = webcam.read()\n",
    "    if not exito :\n",
    "        break\n",
    "    frame_clasificado = model(frame,mode=\"predict\",show = True)\n",
    "\n",
    "    cv.imshow(\"Webcam\", frame)\n",
    "    cv.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_v8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "75083f7d38161667999e0a8dd22686fa7212ca94da81e178ebec3868e23e81f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
